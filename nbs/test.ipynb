{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"   # see issue #152\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"6\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "from src import milan, milannotations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "load alexnet/imagenet: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 5/5 [00:09<00:00,  1.88s/it]\n"
     ]
    }
   ],
   "source": [
    "alexnet_imagenet = milannotations.load('alexnet/imagenet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alexnet_imagenet.samples_by_layer_unit[('conv4', 113)].annotations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('conv5', 0),\n",
       " ('conv5', 1),\n",
       " ('conv5', 2),\n",
       " ('conv5', 3),\n",
       " ('conv5', 4),\n",
       " ('conv5', 5),\n",
       " ('conv5', 6),\n",
       " ('conv5', 7),\n",
       " ('conv5', 8),\n",
       " ('conv5', 9),\n",
       " ('conv5', 10),\n",
       " ('conv5', 11),\n",
       " ('conv5', 12),\n",
       " ('conv5', 13),\n",
       " ('conv5', 14),\n",
       " ('conv5', 15),\n",
       " ('conv5', 16),\n",
       " ('conv5', 17),\n",
       " ('conv5', 18),\n",
       " ('conv5', 19),\n",
       " ('conv5', 20),\n",
       " ('conv5', 21),\n",
       " ('conv5', 22),\n",
       " ('conv5', 23),\n",
       " ('conv5', 24),\n",
       " ('conv5', 25),\n",
       " ('conv5', 26),\n",
       " ('conv5', 27),\n",
       " ('conv5', 28),\n",
       " ('conv5', 29),\n",
       " ('conv5', 30),\n",
       " ('conv5', 31),\n",
       " ('conv5', 32),\n",
       " ('conv5', 33),\n",
       " ('conv5', 34),\n",
       " ('conv5', 35),\n",
       " ('conv5', 36),\n",
       " ('conv5', 37),\n",
       " ('conv5', 38),\n",
       " ('conv5', 39),\n",
       " ('conv5', 40),\n",
       " ('conv5', 41),\n",
       " ('conv5', 42),\n",
       " ('conv5', 43),\n",
       " ('conv5', 44),\n",
       " ('conv5', 45),\n",
       " ('conv5', 46),\n",
       " ('conv5', 47),\n",
       " ('conv5', 48),\n",
       " ('conv5', 49),\n",
       " ('conv5', 50),\n",
       " ('conv5', 51),\n",
       " ('conv5', 52),\n",
       " ('conv5', 53),\n",
       " ('conv5', 54),\n",
       " ('conv5', 55),\n",
       " ('conv5', 56),\n",
       " ('conv5', 57),\n",
       " ('conv5', 58),\n",
       " ('conv5', 59),\n",
       " ('conv5', 60),\n",
       " ('conv5', 61),\n",
       " ('conv5', 62),\n",
       " ('conv5', 63),\n",
       " ('conv5', 64),\n",
       " ('conv5', 65),\n",
       " ('conv5', 66),\n",
       " ('conv5', 67),\n",
       " ('conv5', 68),\n",
       " ('conv5', 69),\n",
       " ('conv5', 70),\n",
       " ('conv5', 71),\n",
       " ('conv5', 72),\n",
       " ('conv5', 73),\n",
       " ('conv5', 74),\n",
       " ('conv5', 75),\n",
       " ('conv5', 76),\n",
       " ('conv5', 77),\n",
       " ('conv5', 78),\n",
       " ('conv5', 79),\n",
       " ('conv5', 80),\n",
       " ('conv5', 81),\n",
       " ('conv5', 82),\n",
       " ('conv5', 83),\n",
       " ('conv5', 84),\n",
       " ('conv5', 85),\n",
       " ('conv5', 86),\n",
       " ('conv5', 87),\n",
       " ('conv5', 88),\n",
       " ('conv5', 89),\n",
       " ('conv5', 90),\n",
       " ('conv5', 91),\n",
       " ('conv5', 92),\n",
       " ('conv5', 93),\n",
       " ('conv5', 94),\n",
       " ('conv5', 95),\n",
       " ('conv5', 96),\n",
       " ('conv5', 97),\n",
       " ('conv5', 98),\n",
       " ('conv5', 99),\n",
       " ('conv5', 100),\n",
       " ('conv5', 101),\n",
       " ('conv5', 102),\n",
       " ('conv5', 103),\n",
       " ('conv5', 104),\n",
       " ('conv5', 105),\n",
       " ('conv5', 106),\n",
       " ('conv5', 107),\n",
       " ('conv5', 108),\n",
       " ('conv5', 109),\n",
       " ('conv5', 110),\n",
       " ('conv5', 111),\n",
       " ('conv5', 112),\n",
       " ('conv5', 113),\n",
       " ('conv5', 114),\n",
       " ('conv5', 115),\n",
       " ('conv5', 116),\n",
       " ('conv5', 117),\n",
       " ('conv5', 118),\n",
       " ('conv5', 119),\n",
       " ('conv5', 120),\n",
       " ('conv5', 121),\n",
       " ('conv5', 122),\n",
       " ('conv5', 123),\n",
       " ('conv5', 124),\n",
       " ('conv5', 125),\n",
       " ('conv5', 126),\n",
       " ('conv5', 127),\n",
       " ('conv5', 128),\n",
       " ('conv5', 129),\n",
       " ('conv5', 130),\n",
       " ('conv5', 131),\n",
       " ('conv5', 132),\n",
       " ('conv5', 133),\n",
       " ('conv5', 134),\n",
       " ('conv5', 135),\n",
       " ('conv5', 136),\n",
       " ('conv5', 137),\n",
       " ('conv5', 138),\n",
       " ('conv5', 139),\n",
       " ('conv5', 140),\n",
       " ('conv5', 141),\n",
       " ('conv5', 142),\n",
       " ('conv5', 143),\n",
       " ('conv5', 144),\n",
       " ('conv5', 145),\n",
       " ('conv5', 146),\n",
       " ('conv5', 147),\n",
       " ('conv5', 148),\n",
       " ('conv5', 149),\n",
       " ('conv5', 150),\n",
       " ('conv5', 151),\n",
       " ('conv5', 152),\n",
       " ('conv5', 153),\n",
       " ('conv5', 154),\n",
       " ('conv5', 155),\n",
       " ('conv5', 156),\n",
       " ('conv5', 157),\n",
       " ('conv5', 158),\n",
       " ('conv5', 159),\n",
       " ('conv5', 160),\n",
       " ('conv5', 161),\n",
       " ('conv5', 162),\n",
       " ('conv5', 163),\n",
       " ('conv5', 164),\n",
       " ('conv5', 165),\n",
       " ('conv5', 166),\n",
       " ('conv5', 167),\n",
       " ('conv5', 168),\n",
       " ('conv5', 169),\n",
       " ('conv5', 170),\n",
       " ('conv5', 171),\n",
       " ('conv5', 172),\n",
       " ('conv5', 173),\n",
       " ('conv5', 174),\n",
       " ('conv5', 175),\n",
       " ('conv5', 176),\n",
       " ('conv5', 177),\n",
       " ('conv5', 178),\n",
       " ('conv5', 179),\n",
       " ('conv5', 180),\n",
       " ('conv5', 181),\n",
       " ('conv5', 182),\n",
       " ('conv5', 183),\n",
       " ('conv5', 184),\n",
       " ('conv5', 185),\n",
       " ('conv5', 186),\n",
       " ('conv5', 187),\n",
       " ('conv5', 188),\n",
       " ('conv5', 189),\n",
       " ('conv5', 190),\n",
       " ('conv5', 191),\n",
       " ('conv5', 192),\n",
       " ('conv5', 193),\n",
       " ('conv5', 194),\n",
       " ('conv5', 195),\n",
       " ('conv5', 196),\n",
       " ('conv5', 197),\n",
       " ('conv5', 198),\n",
       " ('conv5', 199),\n",
       " ('conv5', 200),\n",
       " ('conv5', 201),\n",
       " ('conv5', 202),\n",
       " ('conv5', 203),\n",
       " ('conv5', 204),\n",
       " ('conv5', 205),\n",
       " ('conv5', 206),\n",
       " ('conv5', 207),\n",
       " ('conv5', 208),\n",
       " ('conv5', 209),\n",
       " ('conv5', 210),\n",
       " ('conv5', 211),\n",
       " ('conv5', 212),\n",
       " ('conv5', 213),\n",
       " ('conv5', 214),\n",
       " ('conv5', 215),\n",
       " ('conv5', 216),\n",
       " ('conv5', 217),\n",
       " ('conv5', 218),\n",
       " ('conv5', 219),\n",
       " ('conv5', 220),\n",
       " ('conv5', 221),\n",
       " ('conv5', 222),\n",
       " ('conv5', 223),\n",
       " ('conv5', 224),\n",
       " ('conv5', 225),\n",
       " ('conv5', 226),\n",
       " ('conv5', 227),\n",
       " ('conv5', 228),\n",
       " ('conv5', 229),\n",
       " ('conv5', 230),\n",
       " ('conv5', 231),\n",
       " ('conv5', 232),\n",
       " ('conv5', 233),\n",
       " ('conv5', 234),\n",
       " ('conv5', 235),\n",
       " ('conv5', 236),\n",
       " ('conv5', 237),\n",
       " ('conv5', 238),\n",
       " ('conv5', 239),\n",
       " ('conv5', 240),\n",
       " ('conv5', 241),\n",
       " ('conv5', 242),\n",
       " ('conv5', 243),\n",
       " ('conv5', 244),\n",
       " ('conv5', 245),\n",
       " ('conv5', 246),\n",
       " ('conv5', 247),\n",
       " ('conv5', 248),\n",
       " ('conv5', 249),\n",
       " ('conv5', 250),\n",
       " ('conv5', 251),\n",
       " ('conv5', 252),\n",
       " ('conv5', 253),\n",
       " ('conv5', 254),\n",
       " ('conv5', 255)]"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "key_lst = [key for key in alexnet_imagenet.samples_by_layer_unit.keys() if key[0] == 'conv5']\n",
    "sorted(key_lst, key = lambda x: x[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder = milan.pretrained('alexnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.exemplars.models import default_model_configs\n",
    "from src.exemplars.models import load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'factory': <function src.deps.ext.torchvision.models.alexnet_seq(**kwargs: Any) -> torch.nn.modules.container.Sequential>,\n",
       " 'defaults': {'pretrained': True},\n",
       " 'url': None,\n",
       " 'requires_path': False,\n",
       " 'load_weights': False,\n",
       " 'transform_weights': None,\n",
       " 'layers': ['conv1', 'conv2', 'conv3', 'conv4', 'conv5'],\n",
       " 'exemplars': ModelExemplarsConfig(k=None, quantile=None, output_size=None, batch_size=None, image_size=None, renormalizer=None)}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "default_model_configs()['alexnet/imagenet'].__dict__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "model, layer, config = load('alexnet/imagenet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 1000])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test = torch.randn(1, 3, 224, 224)\n",
    "model(X_test).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.randn(10, 1000, requires_grad=True)\n",
    "out = torch.index_select(x, 1, torch.tensor([0, 2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10, 2])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (conv1): Conv2d(3, 64, kernel_size=(11, 11), stride=(4, 4), padding=(2, 2))\n",
       "  (relu1): ReLU(inplace=True)\n",
       "  (pool1): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (conv2): Conv2d(64, 192, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
       "  (relu2): ReLU(inplace=True)\n",
       "  (pool2): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (conv3): Conv2d(192, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (relu3): ReLU(inplace=True)\n",
       "  (conv4): Conv2d(384, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (relu4): ReLU(inplace=True)\n",
       "  (conv5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (relu5): ReLU(inplace=True)\n",
       "  (pool5): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(6, 6))\n",
       "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
       "  (dropout6): Dropout(p=0.5, inplace=False)\n",
       "  (fc6): Linear(in_features=9216, out_features=4096, bias=True)\n",
       "  (relu6): ReLU(inplace=True)\n",
       "  (dropout7): Dropout(p=0.5, inplace=False)\n",
       "  (fc7): Linear(in_features=4096, out_features=4096, bias=True)\n",
       "  (relu7): ReLU(inplace=True)\n",
       "  (linear8): Linear(in_features=4096, out_features=1000, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 64, 55, 55])\n",
      "tensor([[[[-0., -0., 0.,  ..., -0., -0., 0.],\n",
      "          [-0., 0., -0.,  ..., 0., 0., -0.],\n",
      "          [-0., 0., -0.,  ..., -0., -0., -0.],\n",
      "          ...,\n",
      "          [-0., 0., -0.,  ..., -0., 0., 0.],\n",
      "          [-0., -0., 0.,  ..., 0., -0., -0.],\n",
      "          [-0., -0., -0.,  ..., -0., -0., -0.]],\n",
      "\n",
      "         [[-0., -0., -0.,  ..., -0., -0., -0.],\n",
      "          [-0., -0., -0.,  ..., -0., -0., -0.],\n",
      "          [-0., -0., -0.,  ..., -0., -0., -0.],\n",
      "          ...,\n",
      "          [-0., -0., -0.,  ..., -0., -0., -0.],\n",
      "          [-0., -0., -0.,  ..., -0., -0., -0.],\n",
      "          [-0., -0., -0.,  ..., -0., -0., -0.]],\n",
      "\n",
      "         [[0., -0., -0.,  ..., 0., 0., -0.],\n",
      "          [0., -0., -0.,  ..., -0., 0., 0.],\n",
      "          [-0., -0., -0.,  ..., -0., -0., -0.],\n",
      "          ...,\n",
      "          [0., -0., 0.,  ..., 0., -0., 0.],\n",
      "          [0., -0., 0.,  ..., 0., -0., -0.],\n",
      "          [-0., -0., -0.,  ..., 0., -0., -0.]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[0., 0., -0.,  ..., -0., -0., -0.],\n",
      "          [0., 0., 0.,  ..., -0., 0., -0.],\n",
      "          [0., -0., -0.,  ..., 0., 0., -0.],\n",
      "          ...,\n",
      "          [-0., -0., 0.,  ..., 0., 0., 0.],\n",
      "          [-0., -0., 0.,  ..., -0., -0., -0.],\n",
      "          [-0., 0., 0.,  ..., 0., 0., -0.]],\n",
      "\n",
      "         [[0., 0., -0.,  ..., -0., -0., -0.],\n",
      "          [-0., -0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., -0., -0.,  ..., 0., -0., -0.],\n",
      "          ...,\n",
      "          [-0., -0., 0.,  ..., 0., -0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., -0., -0.],\n",
      "          [-0., -0., -0.,  ..., 0., 0., 0.]],\n",
      "\n",
      "         [[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., -0., -0.,  ..., -0., -0., -0.],\n",
      "          [-0., -0., 0.,  ..., 0., 0., -0.],\n",
      "          ...,\n",
      "          [-0., -0., -0.,  ..., -0., 0., -0.],\n",
      "          [0., -0., -0.,  ..., -0., -0., 0.],\n",
      "          [-0., -0., 0.,  ..., 0., -0., -0.]]]], grad_fn=<MulBackward0>)\n",
      "torch.Size([1, 192, 27, 27])\n",
      "tensor([[[[-0., -0., -0.,  ..., -0., -0., -0.],\n",
      "          [-0., -0., -0.,  ..., -0., -0., -0.],\n",
      "          [-0., -0., -0.,  ..., -0., -0., -0.],\n",
      "          ...,\n",
      "          [-0., -0., -0.,  ..., -0., -0., -0.],\n",
      "          [-0., -0., -0.,  ..., -0., -0., -0.],\n",
      "          [-0., -0., -0.,  ..., -0., -0., -0.]],\n",
      "\n",
      "         [[-0., -0., -0.,  ..., -0., -0., -0.],\n",
      "          [-0., -0., -0.,  ..., -0., -0., -0.],\n",
      "          [-0., -0., -0.,  ..., -0., -0., -0.],\n",
      "          ...,\n",
      "          [-0., -0., -0.,  ..., -0., -0., -0.],\n",
      "          [-0., -0., -0.,  ..., -0., -0., -0.],\n",
      "          [-0., -0., -0.,  ..., -0., -0., -0.]],\n",
      "\n",
      "         [[-0., -0., -0.,  ..., -0., -0., -0.],\n",
      "          [-0., -0., -0.,  ..., -0., -0., -0.],\n",
      "          [-0., -0., -0.,  ..., -0., -0., -0.],\n",
      "          ...,\n",
      "          [-0., -0., -0.,  ..., -0., -0., -0.],\n",
      "          [-0., -0., -0.,  ..., -0., -0., -0.],\n",
      "          [-0., -0., -0.,  ..., -0., -0., -0.]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          ...,\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.]],\n",
      "\n",
      "         [[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          ...,\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.]],\n",
      "\n",
      "         [[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          ...,\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.]]]], grad_fn=<MulBackward0>)\n",
      "torch.Size([1, 384, 13, 13])\n",
      "tensor([[[[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          ...,\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.]],\n",
      "\n",
      "         [[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          ...,\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.]],\n",
      "\n",
      "         [[-0., -0., -0.,  ..., -0., -0., -0.],\n",
      "          [-0., -0., -0.,  ..., -0., -0., -0.],\n",
      "          [-0., -0., -0.,  ..., -0., -0., -0.],\n",
      "          ...,\n",
      "          [-0., -0., -0.,  ..., -0., -0., -0.],\n",
      "          [-0., -0., -0.,  ..., -0., -0., -0.],\n",
      "          [-0., -0., -0.,  ..., -0., -0., -0.]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0., -0., -0.,  ..., -0., -0., -0.],\n",
      "          [-0., -0., -0.,  ..., -0., -0., -0.],\n",
      "          [-0., -0., -0.,  ..., -0., -0., -0.],\n",
      "          ...,\n",
      "          [-0., -0., -0.,  ..., -0., -0., -0.],\n",
      "          [-0., -0., -0.,  ..., -0., -0., -0.],\n",
      "          [-0., -0., -0.,  ..., -0., -0., -0.]],\n",
      "\n",
      "         [[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          ...,\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.]],\n",
      "\n",
      "         [[-0., -0., -0.,  ..., -0., -0., -0.],\n",
      "          [-0., -0., -0.,  ..., -0., -0., -0.],\n",
      "          [-0., -0., -0.,  ..., -0., -0., -0.],\n",
      "          ...,\n",
      "          [-0., -0., -0.,  ..., -0., -0., -0.],\n",
      "          [-0., -0., -0.,  ..., -0., -0., -0.],\n",
      "          [-0., -0., -0.,  ..., -0., -0., -0.]]]], grad_fn=<MulBackward0>)\n",
      "torch.Size([1, 256, 13, 13])\n",
      "tensor([[[[-0., -0., -0.,  ..., -0., -0., -0.],\n",
      "          [-0., -0., -0.,  ..., -0., -0., -0.],\n",
      "          [-0., -0., -0.,  ..., -0., -0., -0.],\n",
      "          ...,\n",
      "          [-0., -0., -0.,  ..., -0., -0., -0.],\n",
      "          [-0., -0., -0.,  ..., -0., -0., -0.],\n",
      "          [-0., -0., -0.,  ..., -0., -0., -0.]],\n",
      "\n",
      "         [[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          ...,\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.]],\n",
      "\n",
      "         [[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          ...,\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          ...,\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.]],\n",
      "\n",
      "         [[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          ...,\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.]],\n",
      "\n",
      "         [[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          ...,\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.]]]], grad_fn=<MulBackward0>)\n",
      "torch.Size([1, 256, 13, 13])\n",
      "tensor([[[[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          ...,\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.]],\n",
      "\n",
      "         [[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          ...,\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.]],\n",
      "\n",
      "         [[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          ...,\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          ...,\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.]],\n",
      "\n",
      "         [[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          ...,\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.]],\n",
      "\n",
      "         [[-0., -0., -0.,  ..., -0., -0., -0.],\n",
      "          [-0., -0., -0.,  ..., -0., -0., -0.],\n",
      "          [-0., -0., -0.,  ..., -0., -0., -0.],\n",
      "          ...,\n",
      "          [-0., -0., -0.,  ..., -0., -0., -0.],\n",
      "          [-0., -0., -0.,  ..., -0., -0., -0.],\n",
      "          [-0., -0., -0.,  ..., -0., -0., -0.]]]], grad_fn=<MulBackward0>)\n",
      "tensor([[ 2.4243e-01, -6.4888e-02,  3.5834e-02,  5.7330e-02,  1.6874e-02,\n",
      "          2.5644e-01,  2.4395e-01,  5.5394e-02,  3.8920e-02,  1.5972e-01,\n",
      "         -4.7712e-02, -1.1400e-01,  1.2694e-01,  1.5628e-01, -3.9977e-02,\n",
      "         -3.1965e-02,  1.5783e-02,  2.2500e-02, -3.9747e-02,  9.9489e-02,\n",
      "          1.3660e-01,  1.9969e-01,  1.5295e-01,  1.5571e-01,  9.9422e-02,\n",
      "         -2.5120e-01, -3.8452e-02, -1.6325e-01, -2.4509e-01,  4.6675e-01,\n",
      "          4.7532e-02, -5.5484e-03,  1.7761e-02,  1.1819e-01,  1.5384e-01,\n",
      "          1.6144e-02,  1.8402e-01, -3.5574e-02,  1.7264e-01,  2.5052e-01,\n",
      "         -1.9901e-02,  4.7706e-02,  8.2804e-02,  2.7805e-01,  1.1463e-01,\n",
      "          6.0915e-02,  1.9742e-02,  2.4280e-01,  2.0250e-01,  1.8130e-01,\n",
      "          1.2192e-01,  2.2147e-01, -6.4707e-02, -4.2559e-02, -2.0544e-03,\n",
      "         -1.6962e-01, -1.2194e-01, -1.4562e-01,  1.0127e-01,  7.9394e-03,\n",
      "          1.2771e-02,  1.5985e-02,  8.2916e-02,  4.1179e-01,  1.8899e-01,\n",
      "          3.6018e-02,  1.1913e-01,  1.0165e-01,  3.7497e-02,  2.0499e-01,\n",
      "         -1.5785e-01,  1.0266e-01, -7.7985e-02,  9.5826e-02, -6.4506e-02,\n",
      "          5.1854e-02,  2.3612e-01,  4.6000e-02,  1.3268e-01,  1.0574e-01,\n",
      "          6.0420e-02, -4.5277e-02,  7.9994e-02,  8.2825e-02,  9.3856e-02,\n",
      "          2.2821e-01,  1.5086e-01,  2.7830e-01,  4.9857e-02,  1.8961e-01,\n",
      "         -1.3359e-01,  2.1556e-02, -1.7151e-01,  2.1923e-01,  3.1105e-01,\n",
      "         -5.1447e-02,  1.3326e-01,  1.6868e-02,  1.9591e-02,  6.3817e-02,\n",
      "          1.3681e-02,  2.0791e-01,  1.3619e-01,  3.5645e-01,  3.3149e-01,\n",
      "          2.4772e-01,  3.3741e-01, -1.1232e-01, -1.0465e-01, -2.3278e-01,\n",
      "         -2.0724e-01, -4.3754e-02,  1.2278e-01,  1.1441e-01,  1.2273e-01,\n",
      "         -3.1063e-01,  3.0848e-02,  1.5869e-01, -1.0587e-01, -8.8580e-02,\n",
      "          9.5180e-02, -2.0525e-01, -8.3153e-02, -1.0134e-01, -6.6338e-02,\n",
      "          1.2893e-01,  2.2368e-01, -4.8186e-02,  1.1474e-01,  8.3894e-02,\n",
      "         -2.2101e-01, -4.6798e-02,  4.7043e-02, -2.5584e-02, -5.5876e-02,\n",
      "         -9.2736e-02, -1.1834e-01, -1.3701e-02,  9.1335e-02, -8.9884e-02,\n",
      "          2.0673e-02, -4.4507e-02, -8.3704e-02, -1.4742e-01, -7.1014e-03,\n",
      "         -4.6470e-03,  9.6858e-02, -1.1149e-01, -6.3273e-02,  1.1869e-01,\n",
      "          2.1161e-01,  2.6585e-01, -8.1097e-02,  2.5272e-01,  1.9468e-01,\n",
      "          2.1562e-01,  1.7370e-01,  1.7904e-01,  7.2192e-02,  2.2268e-02,\n",
      "          2.0877e-01,  2.3882e-01,  2.4063e-01,  2.3314e-01,  2.5775e-01,\n",
      "         -7.0101e-03,  1.0299e-01, -5.2085e-02,  1.9014e-01,  1.7101e-01,\n",
      "          2.5171e-01,  3.6244e-01,  1.9027e-01,  1.1518e-01,  3.3488e-01,\n",
      "         -1.4710e-02,  2.2397e-01,  2.7233e-01,  1.9120e-01,  1.5660e-01,\n",
      "          2.0898e-01,  2.4180e-01,  2.3373e-01,  2.1838e-01,  1.0242e-01,\n",
      "          4.8781e-02,  1.7931e-01,  1.5856e-01,  1.0871e-01,  3.3717e-01,\n",
      "          1.4020e-01,  2.7256e-01,  3.2063e-01,  8.7052e-02,  9.1095e-02,\n",
      "          2.2172e-01,  2.8019e-01,  1.6151e-01,  1.2957e-01,  3.9162e-01,\n",
      "          3.1121e-02,  8.7126e-02,  3.1449e-01,  2.9044e-01,  2.2314e-01,\n",
      "          1.3472e-01,  1.5613e-01,  1.1647e-01,  2.1161e-01,  3.2164e-01,\n",
      "          1.2457e-01,  5.9141e-02,  2.2585e-01,  4.2928e-02,  5.8941e-02,\n",
      "          1.4758e-01,  1.3074e-01,  2.4227e-01,  1.4833e-01,  1.2254e-01,\n",
      "          7.4971e-02,  6.6415e-02,  2.9290e-01,  3.6718e-01,  1.0333e-01,\n",
      "          3.2510e-01,  1.9814e-01,  1.3765e-01,  2.2960e-01,  3.0017e-01,\n",
      "          2.6641e-01,  7.7480e-02,  1.3212e-01,  2.0285e-01,  1.2889e-01,\n",
      "          2.0043e-01,  1.3045e-01,  2.3903e-01,  1.6992e-01,  2.3383e-01,\n",
      "          1.1357e-01,  9.3778e-02,  1.9048e-01,  2.0367e-01,  1.1319e-01,\n",
      "          2.0394e-01,  1.6201e-01,  2.3013e-01,  1.1195e-01,  1.9722e-01,\n",
      "          2.5316e-01,  2.3265e-02,  1.1665e-01,  1.1911e-01,  2.8486e-01,\n",
      "          8.2387e-02,  1.3520e-01,  2.6346e-01,  2.2740e-01,  2.1398e-01,\n",
      "          2.3250e-01,  1.4764e-01,  2.8620e-02,  2.7274e-01,  1.1750e-01,\n",
      "          2.8582e-01,  2.8236e-01,  1.1898e-01,  8.6556e-02,  1.7619e-01,\n",
      "          2.6470e-01,  2.1833e-01,  2.3609e-01,  2.4255e-01,  1.8788e-01,\n",
      "          7.0026e-02,  1.9733e-01,  2.0444e-01,  1.2882e-01,  2.5806e-01,\n",
      "          2.3056e-01,  3.3647e-01,  2.1076e-01,  2.1062e-01,  2.9784e-01,\n",
      "          3.3940e-01,  3.3142e-01,  2.0851e-01, -1.2282e-02,  1.4655e-01,\n",
      "         -3.9405e-02,  1.4366e-01,  9.6591e-02, -2.5727e-02,  8.0163e-02,\n",
      "          1.5298e-01,  2.2234e-01,  2.1652e-01,  2.0292e-01,  2.8321e-01,\n",
      "         -1.8791e-01, -1.8943e-01, -7.5652e-02, -8.4702e-02, -2.1671e-01,\n",
      "          4.5220e-03,  1.4749e-01, -1.9084e-01,  1.1662e-02, -1.4982e-01,\n",
      "         -5.6560e-02, -8.8018e-02, -7.8901e-02, -8.6754e-03,  9.1267e-02,\n",
      "          7.8447e-02,  1.4209e-01, -1.1633e-02,  1.3014e-01, -8.7503e-02,\n",
      "         -1.8406e-01, -2.2522e-01, -1.1445e-01, -4.1461e-01,  6.9911e-02,\n",
      "         -2.3267e-01,  8.7109e-03, -1.3885e-01, -2.8484e-02, -6.7881e-02,\n",
      "          3.0803e-01,  2.3488e-01,  3.8054e-01,  2.4527e-01,  3.0341e-01,\n",
      "          2.1867e-01,  1.6896e-01,  2.7477e-01,  1.0905e-01,  2.2730e-02,\n",
      "          1.2132e-02,  1.7251e-01,  2.1157e-01,  2.3863e-01,  1.8773e-01,\n",
      "          1.5180e-01,  1.9334e-01,  9.7182e-02,  1.3234e-01,  1.8249e-01,\n",
      "          2.5858e-01,  7.2333e-02,  1.3360e-02,  1.1019e-01,  2.4862e-01,\n",
      "          1.8533e-01,  3.2479e-01,  2.8326e-01,  4.0866e-01,  4.0507e-01,\n",
      "          2.1714e-01,  3.8936e-01,  2.7894e-01,  3.4671e-01,  1.7375e-01,\n",
      "          1.5581e-01,  1.4502e-01,  2.4948e-01,  7.5643e-02,  1.5869e-01,\n",
      "          1.6562e-01,  2.4657e-01,  2.6752e-01,  2.5558e-01,  2.3387e-01,\n",
      "          9.9342e-02,  8.5303e-02,  2.6576e-01,  2.5198e-01,  3.4975e-02,\n",
      "          2.7302e-01,  1.7827e-01,  2.3846e-01,  1.5827e-01,  9.2291e-02,\n",
      "          1.5482e-01,  1.2354e-01,  1.8410e-01,  2.0705e-01,  2.3325e-01,\n",
      "          6.6578e-02,  1.7144e-01, -1.9150e-01, -2.8481e-01,  1.6616e-01,\n",
      "          1.7910e-01, -8.2789e-02,  1.5488e-01, -1.7890e-01,  4.6739e-03,\n",
      "         -2.0681e-01,  3.0475e-02, -5.9437e-02, -1.9292e-01, -3.4336e-01,\n",
      "          5.6760e-02, -2.8223e-01, -2.5929e-01, -2.0362e-01, -1.6949e-01,\n",
      "          1.8568e-01, -5.9545e-02,  1.2114e-01,  1.6607e-02, -3.3240e-02,\n",
      "         -1.9161e-01,  6.9452e-03, -3.4982e-02, -9.7995e-02,  9.7701e-02,\n",
      "          6.7094e-02,  7.0124e-03, -3.3652e-02,  7.1237e-02,  6.1626e-03,\n",
      "         -1.7669e-01, -1.3891e-01, -8.7813e-02,  2.0216e-01,  3.3832e-02,\n",
      "         -7.3710e-02,  1.8689e-01, -1.4186e-01,  8.5783e-02,  5.5785e-02,\n",
      "          1.5983e-01, -2.4567e-01, -1.8695e-01,  1.5712e-02, -1.6662e-02,\n",
      "         -1.1706e-01, -9.9831e-03, -4.3377e-02,  1.0075e-02, -2.0210e-01,\n",
      "         -3.9219e-02, -6.0018e-02,  7.1685e-03,  2.3689e-01, -1.6339e-01,\n",
      "          9.3950e-02, -3.2412e-02,  8.9028e-02, -2.8769e-01, -2.4348e-01,\n",
      "         -8.6392e-02,  1.2901e-01, -2.9863e-02, -1.6587e-01,  3.8925e-02,\n",
      "         -9.7924e-02, -2.5852e-02,  1.3766e-01,  1.1865e-01,  3.7006e-02,\n",
      "          6.4755e-02, -1.1628e-01, -2.1089e-01, -2.3023e-01,  1.9459e-01,\n",
      "         -1.1315e-01,  5.2121e-03, -3.4978e-02,  1.3024e-02, -2.0560e-03,\n",
      "          3.2974e-01, -1.4033e-01, -2.2400e-01,  1.4290e-01, -1.4739e-01,\n",
      "         -4.5262e-02, -2.5239e-02, -2.1419e-01, -2.5741e-01, -3.1663e-01,\n",
      "         -1.7104e-01, -1.5277e-01, -6.8731e-03, -1.7849e-01, -1.8640e-02,\n",
      "         -7.2831e-02,  2.4854e-01,  7.8858e-02, -4.6084e-01, -7.3253e-02,\n",
      "         -3.5043e-01,  1.1580e-01, -4.0979e-01, -2.1192e-01,  1.2293e-02,\n",
      "         -6.0581e-02,  2.4857e-02, -6.8557e-02, -2.2732e-01,  5.0781e-02,\n",
      "         -4.1137e-02, -2.5136e-01, -1.4569e-01, -1.4687e-01, -3.8035e-01,\n",
      "         -3.4760e-01, -2.1436e-01, -1.1293e-01, -1.6092e-01,  8.7329e-02,\n",
      "          1.7490e-01,  6.3535e-02, -2.9355e-01,  6.5294e-02,  3.5168e-04,\n",
      "         -6.8620e-02, -7.5703e-02,  2.1983e-03, -3.7858e-02,  8.6317e-02,\n",
      "          1.2410e-01, -1.7108e-01, -2.6214e-01, -1.3161e-01,  7.3979e-02,\n",
      "         -2.5977e-01, -1.7512e-01, -1.5406e-01, -9.4312e-02,  4.9382e-03,\n",
      "         -1.6492e-01, -4.2221e-01,  8.5239e-02, -2.9065e-01,  1.8988e-01,\n",
      "         -2.8839e-01, -1.2772e-01, -4.1914e-02, -1.0403e-02, -1.0616e-01,\n",
      "          6.4292e-02, -4.4500e-02, -3.8324e-01, -3.6869e-01,  1.4043e-02,\n",
      "         -2.7340e-01, -1.1556e-01, -3.1714e-02, -1.6684e-01, -3.0309e-01,\n",
      "         -3.1379e-01, -7.3192e-02, -2.2320e-02, -3.4770e-02, -1.0003e-01,\n",
      "         -5.7689e-02, -1.3733e-01, -5.5160e-02, -2.7756e-02, -4.5442e-02,\n",
      "         -1.1574e-01, -7.8701e-02, -9.3062e-02,  1.8990e-01, -6.1423e-02,\n",
      "          9.9168e-02, -1.5283e-01, -6.6799e-02,  3.3213e-02,  4.3984e-02,\n",
      "         -4.3078e-02, -1.5822e-01,  7.4286e-02, -8.7869e-02, -1.0598e-01,\n",
      "         -1.4837e-01, -4.1508e-01, -3.0218e-01,  8.3148e-02, -3.1762e-04,\n",
      "         -2.9387e-02, -7.7788e-02,  5.9309e-02, -1.1601e-02,  1.8097e-01,\n",
      "         -3.0058e-01,  1.3806e-02, -1.7477e-01,  1.1339e-01,  4.1260e-02,\n",
      "         -9.8136e-02,  8.8549e-02,  3.1938e-02, -2.7273e-01, -1.1987e-01,\n",
      "          6.9724e-02,  2.1600e-03,  1.4968e-02,  6.6354e-03, -2.8340e-02,\n",
      "         -1.1517e-01,  1.3450e-01, -1.7610e-01, -2.0042e-03, -1.2598e-01,\n",
      "          6.4015e-02,  4.8722e-02, -4.5659e-02, -8.8657e-02, -7.6082e-02,\n",
      "         -1.0899e-01, -5.6436e-02, -4.8344e-03, -1.0520e-02, -1.5224e-01,\n",
      "          8.2732e-02,  4.1764e-02, -9.8842e-03, -4.2098e-02, -4.0147e-01,\n",
      "         -3.3534e-01, -1.0990e-02, -1.1022e-01, -3.4154e-01, -1.1742e-01,\n",
      "          9.0308e-02, -2.2569e-01, -3.0044e-01,  1.3687e-01, -2.8900e-02,\n",
      "         -1.5917e-01, -9.0058e-02, -5.0304e-02, -1.3465e-01, -1.0611e-01,\n",
      "         -2.5100e-01, -1.0576e-01, -2.5986e-02, -4.9933e-02, -6.6947e-02,\n",
      "         -3.1808e-01, -1.0737e-01, -1.5477e-02, -1.9886e-01, -1.2860e-01,\n",
      "         -7.6672e-02, -9.3670e-02,  1.3309e-02,  1.3489e-01, -1.5706e-01,\n",
      "          1.4942e-02, -1.1629e-01, -6.8054e-02,  4.9253e-02, -9.5926e-02,\n",
      "         -5.3255e-02, -2.5116e-01, -3.6487e-02, -2.3194e-01, -1.2302e-01,\n",
      "         -9.6913e-02,  7.3910e-02, -5.4488e-02, -2.6727e-01,  1.5929e-01,\n",
      "         -8.0413e-02, -2.3490e-02,  8.5047e-02, -7.6957e-03,  3.5393e-01,\n",
      "         -1.1716e-01,  2.4193e-01,  9.0095e-02,  5.4276e-02, -2.4004e-01,\n",
      "          8.8641e-02, -5.1835e-02, -2.5368e-01, -2.0271e-01, -4.2970e-02,\n",
      "         -2.6861e-01, -4.7150e-02, -3.7745e-01, -2.2841e-01, -1.6027e-01,\n",
      "          1.1534e-03,  2.0359e-01, -5.9739e-02, -7.0203e-02, -2.0361e-01,\n",
      "          5.6691e-02,  7.4377e-02, -6.3154e-02, -4.2186e-01,  9.3266e-02,\n",
      "          1.9555e-01, -4.8707e-02, -1.7022e-01,  8.6375e-02,  4.9639e-02,\n",
      "         -3.3951e-01,  1.5138e-02,  2.7891e-02, -8.2986e-02, -1.4373e-01,\n",
      "          3.7381e-02, -1.1535e-01, -2.4496e-02,  5.4575e-02, -7.1011e-02,\n",
      "          5.4722e-02,  2.1423e-03, -2.3762e-01, -1.7389e-01,  1.1807e-02,\n",
      "         -1.5368e-02, -6.7527e-02,  8.8470e-02, -9.0950e-02, -3.4074e-01,\n",
      "          3.7664e-02,  4.4396e-02, -1.3651e-01,  1.7903e-01, -1.9901e-01,\n",
      "         -6.1911e-02,  1.3705e-01, -4.6133e-02, -5.8276e-02, -3.2014e-01,\n",
      "          7.4161e-02, -2.1358e-01, -1.5056e-01,  2.0488e-01,  1.6262e-01,\n",
      "          6.2797e-03, -6.3655e-02, -2.7620e-02, -3.8796e-02, -1.2362e-01,\n",
      "         -3.0594e-02, -7.6634e-02,  6.8051e-02,  4.2924e-03,  2.8585e-01,\n",
      "          4.0098e-02, -1.5313e-01,  6.6775e-02,  1.2958e-01, -3.0629e-01,\n",
      "          2.2974e-02,  2.6760e-01, -1.8716e-01, -4.8853e-02, -1.6536e-01,\n",
      "          3.3125e-02,  5.8570e-02, -2.9578e-01,  1.0438e-01,  2.2864e-02,\n",
      "         -8.5696e-04, -8.6660e-02, -5.7472e-02,  3.2805e-02,  6.0080e-02,\n",
      "          5.8074e-02, -1.5257e-01, -3.2031e-03, -1.1776e-01,  4.2441e-02,\n",
      "         -1.2933e-02, -3.5944e-02,  5.3070e-02, -6.5593e-02, -3.1661e-01,\n",
      "         -2.1654e-01, -3.2393e-01, -1.0586e-01,  5.1502e-02, -5.3077e-03,\n",
      "          2.1751e-01,  3.2020e-02,  4.6653e-02, -1.8035e-01, -2.9928e-01,\n",
      "         -3.5000e-02,  2.0122e-03,  1.9000e-01,  1.5916e-01,  5.1443e-02,\n",
      "         -4.1921e-02,  2.0815e-01,  3.4427e-02, -2.0145e-01, -4.4442e-02,\n",
      "         -3.3326e-01,  5.5765e-02,  4.0097e-02, -5.0172e-02,  4.3401e-02,\n",
      "          1.4475e-01, -9.6768e-02,  2.6936e-02,  1.0622e-01, -9.8393e-02,\n",
      "         -3.3097e-01,  7.1491e-02, -6.7937e-02,  7.7533e-02, -1.2007e-01,\n",
      "         -1.0341e-01,  1.2531e-01, -3.5328e-01, -6.9828e-02, -1.7812e-01,\n",
      "         -1.4665e-01, -2.8961e-01, -8.4406e-02, -3.3017e-02, -3.4661e-02,\n",
      "         -2.3706e-01, -1.8299e-01, -1.7672e-01, -1.2402e-02, -2.9352e-01,\n",
      "         -4.9357e-02,  1.1108e-01, -1.5087e-01, -9.6150e-02, -3.3111e-02,\n",
      "          8.0548e-02,  1.5287e-01,  1.7309e-01, -3.2736e-02, -1.6693e-01,\n",
      "          1.4971e-01, -3.2762e-02, -2.6072e-03,  1.3775e-01, -1.1012e-01,\n",
      "          1.0853e-01, -3.9541e-02,  7.5690e-03, -1.9884e-01, -5.8493e-02,\n",
      "          5.0614e-02, -2.5763e-02,  1.0722e-01, -2.7038e-02, -3.0855e-01,\n",
      "          2.0661e-01, -1.5214e-01, -2.3209e-01, -2.9112e-01,  9.6579e-02,\n",
      "         -3.7663e-01,  8.0188e-02, -7.1647e-02, -4.0887e-02, -2.2765e-01,\n",
      "         -2.3866e-01, -9.1791e-02, -1.8400e-01, -8.1592e-02, -2.0842e-01,\n",
      "          9.2135e-02, -3.3314e-01, -1.5362e-01, -2.9037e-01, -3.6728e-01,\n",
      "         -1.0954e-01,  1.4663e-01, -1.6512e-01, -3.3478e-01, -2.4362e-02,\n",
      "          9.9857e-02, -1.6636e-01,  2.7728e-02,  5.2536e-02, -1.6359e-01,\n",
      "         -2.1200e-01, -2.9008e-01, -1.2331e-01, -1.6419e-01, -6.8236e-02,\n",
      "         -1.0489e-01, -7.4352e-02, -9.3048e-02,  2.3103e-02, -2.8116e-01,\n",
      "         -2.0037e-01,  9.3700e-03,  5.7368e-02,  2.3345e-02,  1.9335e-03,\n",
      "         -1.3372e-01, -6.6304e-02, -1.8495e-02,  1.0179e-02,  2.0583e-01,\n",
      "          4.8266e-02, -1.5794e-01, -6.2517e-02, -2.3661e-01,  1.4208e-02,\n",
      "         -9.4994e-02, -3.9300e-02, -1.2221e-02, -6.7790e-02, -1.8470e-01,\n",
      "          1.5235e-02, -1.8500e-01, -1.4414e-01,  1.5390e-01, -4.4761e-02,\n",
      "         -2.2786e-01,  2.2860e-01, -2.0819e-01, -1.5407e-01, -2.0273e-01,\n",
      "         -2.0810e-01, -3.3584e-01, -1.8620e-01, -2.1172e-01,  1.4376e-01,\n",
      "         -3.1988e-01, -2.5385e-01, -2.3719e-01, -2.6772e-01, -2.0326e-01,\n",
      "         -1.8172e-01, -9.2340e-02, -9.8266e-02, -8.5423e-02, -7.0874e-02,\n",
      "         -2.0126e-01, -1.5467e-01, -9.0144e-02, -1.3136e-01, -2.2695e-01,\n",
      "         -2.7082e-01, -3.0156e-01, -1.0775e-01, -9.9494e-02, -3.1156e-01,\n",
      "         -2.8471e-01, -2.9650e-01, -2.2900e-01, -6.4679e-02, -2.4676e-01,\n",
      "         -1.1650e-02,  4.3429e-02, -2.0712e-01, -6.9835e-02, -3.6856e-01,\n",
      "         -1.5526e-01, -3.8761e-02, -1.9328e-01, -3.1457e-01, -2.6367e-01,\n",
      "         -1.6725e-02, -1.0628e-01, -2.4190e-01, -9.3977e-02, -1.0217e-02,\n",
      "         -1.4753e-01,  2.2084e-01, -1.8537e-02, -4.1675e-01, -3.3277e-02,\n",
      "          3.8492e-02, -9.6269e-02,  4.8861e-03, -2.6262e-02, -1.8088e-01,\n",
      "         -3.0104e-02,  3.0908e-02,  2.1342e-02, -1.2837e-01, -2.1773e-01,\n",
      "         -2.4905e-01, -2.7532e-01, -2.4882e-02, -5.5281e-02, -2.5453e-01,\n",
      "         -1.5049e-01, -3.2571e-01, -1.6617e-01, -2.6204e-01, -6.3060e-02,\n",
      "         -1.1386e-01, -8.4411e-02, -6.3339e-02, -1.6700e-02,  1.0885e-01]],\n",
      "       grad_fn=<AddmmBackward0>)\n"
     ]
    }
   ],
   "source": [
    "def multiply_mask(layer, mask):\n",
    "    layer_mask_idx = {\n",
    "        'conv1': torch.arange(0, 64),\n",
    "        'conv2': torch.arange(64, 256),\n",
    "        'conv3': torch.arange(256, 640),\n",
    "        'conv4': torch.arange(640, 896),\n",
    "        'conv5': torch.arange(876, 1132)\n",
    "    }\n",
    "    layer_mask = torch.index_select(mask, 1, layer_mask_idx[layer])\n",
    "    layer_mask = layer_mask[:, :, None, None]\n",
    "    def hook(model, input, output):\n",
    "        print(output.shape)\n",
    "        print(output * layer_mask)\n",
    "        return output * layer_mask\n",
    "    return hook\n",
    "\n",
    "    \n",
    "    \n",
    "mask = torch.zeros(1, 1132)\n",
    "layer_hooks = [None] * 5\n",
    "for hook_idx, layer_idx, layer_name in zip(range(5), [0, 3, 6, 8, 10], ['conv1', 'conv2', 'conv3', 'conv4', 'conv5']):\n",
    "    layer_hook = model[layer_idx].register_forward_hook(multiply_mask(layer_name, mask))\n",
    "    layer_hooks[hook_idx] = layer_hook\n",
    "    \n",
    "\n",
    "\n",
    "output = model(X_test)\n",
    "print(output)\n",
    "\n",
    "for layer_hook in layer_hooks:\n",
    "    layer_hook.remove()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[ 7.0384e-01,  9.0024e-01, -2.6086e-01,  ..., -5.4962e-01,\n",
       "            7.5990e-01,  1.2810e+00],\n",
       "          [ 8.3528e-01, -1.2034e+00,  2.7475e+00,  ..., -1.2221e+00,\n",
       "            4.3180e-01, -6.8186e-01],\n",
       "          [-3.5282e-01,  3.6149e-01, -1.5244e+00,  ...,  5.0769e-01,\n",
       "           -1.7284e+00, -1.2043e-01],\n",
       "          ...,\n",
       "          [ 2.4861e+00,  5.0340e-01, -1.7340e-03,  ..., -1.2344e+00,\n",
       "           -1.5609e+00, -1.0391e+00],\n",
       "          [ 1.3990e+00,  2.5919e+00, -1.4409e+00,  ...,  7.7594e-01,\n",
       "            1.4985e-01,  1.2011e+00],\n",
       "          [-2.4594e+00,  1.2059e-01, -1.3795e-01,  ...,  4.8951e-01,\n",
       "           -8.8356e-01,  1.9623e-01]],\n",
       "\n",
       "         [[-1.0343e+00,  1.0651e+00, -2.0574e-02,  ...,  2.8781e-01,\n",
       "            4.8236e-01, -1.7541e+00],\n",
       "          [-1.6156e+00, -1.6899e+00, -3.0753e-01,  ...,  6.2082e-01,\n",
       "            1.0829e+00, -6.4283e-01],\n",
       "          [ 2.5539e-01, -1.4353e+00,  4.6495e-01,  ..., -8.3487e-01,\n",
       "           -3.9261e-01, -9.6195e-01],\n",
       "          ...,\n",
       "          [-6.7635e-02,  2.1261e+00,  1.5180e-01,  ..., -3.7957e-02,\n",
       "            3.5911e-02,  1.0145e+00],\n",
       "          [-1.2882e-01, -2.8508e-01, -5.2375e-01,  ..., -6.5873e-01,\n",
       "           -5.0181e-01, -1.2662e+00],\n",
       "          [-1.4413e+00, -7.6005e-01, -6.6886e-01,  ...,  4.9550e-01,\n",
       "           -4.2610e-02,  6.0037e-01]],\n",
       "\n",
       "         [[ 4.9415e-01, -6.7693e-01, -5.7074e-01,  ..., -4.9844e-01,\n",
       "           -2.6193e+00,  1.2613e+00],\n",
       "          [-9.7013e-01,  8.3844e-02,  1.0214e-01,  ..., -9.3204e-01,\n",
       "            2.0915e-02, -2.9585e-01],\n",
       "          [ 1.6412e-01, -3.5088e-02,  2.3282e+00,  ...,  1.2837e+00,\n",
       "           -1.6625e+00,  1.8761e+00],\n",
       "          ...,\n",
       "          [ 5.6406e-01,  1.3307e+00,  2.1150e-02,  ...,  4.8472e-01,\n",
       "           -1.4662e+00, -7.8976e-01],\n",
       "          [ 5.3243e-02, -4.8421e-01, -1.2424e-01,  ...,  5.4731e-01,\n",
       "           -9.5842e-01, -1.0709e+00],\n",
       "          [ 7.2281e-01, -1.3446e+00,  6.7596e-01,  ..., -1.6849e+00,\n",
       "            9.9201e-01,  7.7338e-01]]]])"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "neuron",
   "language": "python",
   "name": "neuron"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
